{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cd7e497",
   "metadata": {},
   "source": [
    "### STEP - 1 SCRAPING\n",
    "For which I used the actual NASA site: https://mars.nasa.gov/news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8bc607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b975be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4a0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection\n",
    "db = client.mtm_db\n",
    "collection = db.articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa201ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://mars.nasa.gov/news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cfbbd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with the requests module\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "354084c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa22771",
   "metadata": {},
   "outputs": [],
   "source": [
    "results =(soup.prettify())\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbcb1f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find HTML where title and description reside.\n",
    "results = soup.find_all('div', class_='slide')\n",
    "len(results)\n",
    "# results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8addfc07",
   "metadata": {},
   "source": [
    "##### NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40684c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "News Title = \n",
      "\n",
      "NASA's Perseverance Sheds More Light on Jezero Crater's Watery Past\n",
      "\n",
      "\n",
      "News Paragraph = \n",
      "Pictures from NASA’s latest six-wheeler on the Red Planet suggest the area’s history experienced significant flooding events.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IF I WANT ALL NEWS INDENT THE TRY/EXCEPT AND USE THE FOR LOOP\n",
    "    # loop over results to get article data (just the first [0:1])\n",
    "for result in results[0:1]:\n",
    "\n",
    "# OTHERWISE THIS RETURNS JUST ONE TITLE & ONE DESCRIPTION \n",
    "    try:\n",
    "        # scrape the article title & description\n",
    "        title = result.find('div', class_='content_title' ).text\n",
    "        description = result.find('div', class_='rollover_description_inner').text\n",
    "      \n",
    "        if(title):\n",
    "            print('-------------')\n",
    "            print (f'News Title = {title}')\n",
    "            print (f'News Paragraph = {description}')\n",
    "  \n",
    "    except AttributeError as e:\n",
    "        print(e)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "100b8528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': \"\\n\\nStudy Looks More Closely at Mars' Underground Water Signals\\n\\n\", 'description': '\\nA new paper finds more radar signals suggesting the presence of subsurface ‘lakes,’ but many are in areas too cold for water to remain liquid.\\n', '_id': ObjectId('6197ee70ecc996b377322603')}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to be inserted into MongoDB\n",
    "post = {\n",
    "    'title': title,\n",
    "     'description': description,\n",
    "      }\n",
    "\n",
    "# Insert dictionary into MongoDB as a document\n",
    "collection.insert_one(post)\n",
    "print(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b5a075",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e69fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64148467",
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c5cc88",
   "metadata": {},
   "source": [
    "##### Scrape All Image Urls and Descriptions from the real NASA site - Not Required, Just Curious If I Could Do It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.nasa.gov/topics/moon-to-mars/images'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all pages\n",
    "for x in range(50):\n",
    "    \n",
    "    # HTML object\n",
    "    html = browser.html\n",
    "    \n",
    "    # Parse HTML with Beautiful Soup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Retrieve all elements that contain book information\n",
    "    pics = soup.find_all('div', class_='image')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pics)\n",
    "pics[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    # Iterate through each screen - This requires only one, but I'd like to see how to get all.\n",
    "    for pic in pics:\n",
    "#         Use Beautiful Soup's find() method to navigate and retrieve attributes\n",
    "        div = pic.find('img')\n",
    "        src = div['src']\n",
    "        title = div['alt']\n",
    "        print('-----------')\n",
    "        print(title)\n",
    "        print('https://www.nasa.gov' + src)\n",
    "\n",
    "    # Click the 'more' button on each page\n",
    "    try:\n",
    "        browser.links.find_by_partial_text('MORE IMAGES').click()\n",
    "          \n",
    "    except:\n",
    "        print(\"Scraping Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b674ca31",
   "metadata": {},
   "source": [
    "###### Scrape Successful but button click on \"more images\" unsuccessful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9404e5d",
   "metadata": {},
   "source": [
    "###   - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7c4a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Splinter Browser\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c860c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigating to News Page - Top Event Has Featured Image of the Day\n",
    "url = 'https://mars.nasa.gov/news'\n",
    "\n",
    "# View News Page in Splinter Browser\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cdfe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to large sized featured image - Inspect html for image location.\n",
    "# featured_image_url = \thttps://mars.nasa.gov/system/news_items/main_images/9077_PIA24528-web.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea8f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae112fc",
   "metadata": {},
   "source": [
    "##### Mars Facts - table scraping\n",
    "Using panadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c76f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got to the table web page (Launch Windows)\n",
    "url = 'https://mars.nasa.gov/mars2020/timeline/launch/launch-windows/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a039ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read Launch Windows table\n",
    "tables = pd.read_html(url)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324746b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables is a list\n",
    "type(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put tables into a df\n",
    "launch_df = tables[0]\n",
    "launch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb804da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate HTML from tables dataframe\n",
    "html_launch_tbl = launch_df.to_html()\n",
    "html_launch_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bcc232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data dictionary from Launch Timeline images\n",
    "timeline = {\n",
    "    \"title\": [\"Perserverence Rover Launch\", \"Cruise: 292,526,838 Miles\", \"Descent and Landing\", \"Surface Operations\"],\n",
    "    \"img_url\": [\"https://mars.nasa.gov/imgs/mars2020/launch/liftoff-launch.jpg\", \n",
    "                \"https://mars.nasa.gov/layout/mars2020/images/cruise/NASAeyes_Mars2020_cruise_clip_v2.jpg\",\n",
    "                   \"https://mars.nasa.gov/imgs/mars2020/mars2020-sky-crane.jpg\",\n",
    "                       \"https://mars.nasa.gov/imgs/mars2020/Mars2020-Depot-Caching-animated.gif\"],\n",
    "            }\n",
    "\n",
    "# Create a dataframe from dictionary - Don't Need\n",
    "# timeline_df = pd.DataFrame(timeline)\n",
    "# timeline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc6fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Homework want's the dictionary from above. Don't Use DF - html.\n",
    "\n",
    "\n",
    "# Generate html from timeline dataframe  \n",
    "# html_timeline_tbl = df.to_html()\n",
    "# html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
